{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KMeans_Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "source": [
        "# Game Classification Model"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "UID9RK1qDlVB",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO_1kOEGDTws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "eccc66bd-8b04-4d4f-faa1-b4b0d22df5c8"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn import metrics\n",
        "\n",
        "os.chdir(r\"C:\\Users\\Zack\\Desktop\\work\\OSU\\406 - p2 - learning\\jupyter practice\\final models\")\n",
        "game_data = pd.read_csv('game_data.csv') #names = col_names if not in CSV\n",
        "# game_data.head() # See the first 5 rows"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_pPmK9GIKMz",
        "colab_type": "text"
      },
      "source": [
        "### clean and filter data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WevSKogFEalU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "dc31b65e-b7f5-4116-ec89-5790fdb604bc"
      },
      "source": [
        "# bgg_games = game_data[game_data['type'] == 'boardgame'] # no expansions\n",
        "# bgg_games = bgg_games[bgg_games['year'] > 1980]\n",
        "# bgg_games = game_data[game_data['year'] >= 1980]\n",
        "bgg_games = game_data[game_data['maxplayers'] <= 30]\n",
        "bgg_games = bgg_games[bgg_games['minplaytime'] <= 180] # 120 - 90th percentile\n",
        "bgg_games = bgg_games[bgg_games['maxplaytime'] <= 720]\n",
        "bgg_games = bgg_games[bgg_games['minage'] <= 21]\n",
        "bgg_games = bgg_games[bgg_games['playingtime'] >= 10]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cell for data exploration\n",
        "# bgg_games.columns"
      ]
    },
    {
      "source": [
        "### select cells potentially relevant to categories"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtc_test = bgg_games[['type', 'year', 'minplayers', 'maxplayers', 'playingtime',\n",
        "       'minplaytime', 'maxplaytime', 'minage', 'users_rated', 'avg_rating',\n",
        "       'bay_rating', 'owners', 'traders', 'wanters', 'wishers',\n",
        "       'total_comments', 'total_weights', 'complexity', 'categories',\n",
        "       'mechanics']]\n",
        "dtc_test = dtc_test[dtc_test['maxplayers'] >= dtc_test['minplayers']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for player diff potential and playtime "
      ]
    },
    {
      "source": [
        "#### convert mechanics and categories into lists with values"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtc_test['categories'] = dtc_test['categories'].apply(lambda x: x.strip('][').split(', ') )\n",
        "dtc_test['mechanics'] = dtc_test['mechanics'].apply(lambda x: x.strip('][').split(', ') )"
      ]
    },
    {
      "source": [
        "#### count number of mechanics and categories for each game, make new columns"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtc_test['num_mechs'] = dtc_test.apply(lambda row: len(row['mechanics']), axis=1)\n",
        "dtc_test['num_cats'] = dtc_test.apply(lambda row: len(row['categories']), axis=1)\n",
        "dtc_test['rating_diff'] = dtc_test.avg_rating - dtc_test.bay_rating\n",
        "dtc_test['player_diff'] = dtc_test.maxplayers - dtc_test.minplayers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# explore data\n",
        "# dtc_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data exploration\n",
        "# dtc_test['playingtime'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data exploration\n",
        "# dtc_test.loc[dtc_test.playingtime < 10, 'playingtime'].count()\n",
        "\n",
        "# dtc_test['time_diff'] = dtc_test.maxplaytime - dtc_test.minplaytime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_data_frame_list(df, target_column, output_type=str):\n",
        "    ''' \n",
        "    Accepts a column with list values and splits into several rows.\n",
        "\n",
        "    df: dataframe to split\n",
        "    target_column: the column containing the values to split\n",
        "    output_type: type of all outputs\n",
        "    returns: a dataframe with each entry for the target column separated, with each element moved into a new row. \n",
        "    The values in the other columns are duplicated across the newly divided rows.\n",
        "    '''\n",
        "    row_accumulator = []\n",
        "\n",
        "    def split_list_to_rows(row):\n",
        "        split_row = row[target_column]\n",
        "        if isinstance(split_row, list):\n",
        "          for s in split_row:\n",
        "              new_row = row.to_dict()\n",
        "              new_row[target_column] = output_type(s)\n",
        "              row_accumulator.append(new_row)\n",
        "        else:\n",
        "          new_row = row.to_dict()\n",
        "          new_row[target_column] = output_type(split_row)\n",
        "          row_accumulator.append(new_row)\n",
        "  \n",
        "    df.apply(split_list_to_rows, axis=1)\n",
        "    new_df = pd.DataFrame(row_accumulator)\n",
        "  \n",
        "    return new_df\n",
        "\n",
        "# not needed?!?\n",
        "# def dupe_data_frame_list(df, target_column, output_type=list):\n",
        "#     ''' \n",
        "#     duplicate rows for each value in a list instead (for 'y_test' only)\n",
        "#     '''\n",
        "#     row_accumulator = []\n",
        "\n",
        "#     def dupe_list_to_rows(row):\n",
        "#         split_row = row[target_column]\n",
        "#         if isinstance(split_row, list):\n",
        "#           for s in split_row:\n",
        "#               new_row = row.to_dict()\n",
        "#               new_row[target_column] = output_type(split_row)\n",
        "#               row_accumulator.append(new_row)\n",
        "#         else:\n",
        "#           new_row = row.to_dict()\n",
        "#           new_row[target_column] = output_type(split_row)\n",
        "#           row_accumulator.append(new_row)\n",
        "  \n",
        "#     df.apply(dupe_list_to_rows, axis=1)\n",
        "#     new_df = pd.DataFrame(row_accumulator)\n",
        "  \n",
        "#     return new_df"
      ]
    },
    {
      "source": [
        "#### split lists into multiple rows for decision tree"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TESTING: after data split for train/test portions?\n",
        "# dtc_test = split_data_frame_list(dtc_test, 'categories')\n",
        "dtc_test = split_data_frame_list(dtc_test, 'mechanics')"
      ]
    },
    {
      "source": [
        "#### Before splitting for model, split an test to find old mechanics/categories that are no longer relevant "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "import math\n",
        "# year by which to remove uniques to prevent models from being incompatible\n",
        "\n",
        "break_year = -math.inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "old_mechs = list(dtc_test[dtc_test['year'] < break_year].mechanics.unique())\n",
        "new_mechs = list(dtc_test[dtc_test['year'] >= break_year].mechanics.unique())\n",
        "unique_old_mechs = list(set(old_mechs).difference(new_mechs))\n",
        "\n",
        "# remove rows with irrelevant mechanics\n",
        "dtc_test = dtc_test[~dtc_test.mechanics.isin(unique_old_mechs)]\n",
        "\n",
        "# old_cats = list(temp_frame[temp_frame['year'] < 1980].categories.unique())\n",
        "# new_cats = list(temp_frame[temp_frame['year'] >= 1980].categories.unique())\n",
        "# unique_old_cats = list(set(old_cats).difference(new_cats))"
      ]
    },
    {
      "source": [
        "#### exploration"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # exploration\n",
        "# print(unique_old_mechs)\n",
        "# print(len(dtc_test))\n",
        "# new_df = dtc_test[dtc_test.mechanics.isin(unique_old_mechs)]\n",
        "# print(len(new_df))\n",
        "# new_df.head(10)\n",
        "# one_mech = dtc_test[dtc_test['num_mechs'] == 1]\n",
        "# unique_mech = one_mech[one_mech['mechanics'] == \"'Physical Removal'\"]\n",
        "# unique_mech.head()\n",
        "# print(len(unique_old_cats))\n",
        "# what_war = temp_frame[temp_frame['categories'] == \"'Korean War'\"]\n",
        "# what_years = list(what_war['year'].unique())\n",
        "# print(what_years)\n",
        "# print(len(list(temp_frame[temp_frame['year'] < 1970].categories.unique())))"
      ]
    },
    {
      "source": [
        "#### get all desired cols and apply one-hot fix to categorical features"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for filtering cols\n",
        "desired_cols = ['type', 'year', 'minplayers','maxplayers', 'playingtime', 'minplaytime', 'maxplaytime', 'avg_rating', 'bay_rating', 'complexity', 'categories', 'mechanics', 'num_mechs', 'num_cats', 'minage', 'rating_diff', 'player_diff']\n",
        "#all_cols = ['type', 'year', 'minplayers', 'maxplayers', 'playingtime', 'minplaytime', 'maxplaytime', 'minage', 'users_rated', 'avg_rating', 'bay_rating', 'owners', 'traders', 'wanters', 'wishers', 'total_comments', 'total_weights', 'complexity', 'categories', 'mechanics', 'num_mechs', 'num_cats', 'minage', 'rating_diff', 'player_diff']\n",
        "\n",
        "# make dummies and attach to frame for tree model, leave categories alone\n",
        "total_frame = dtc_test[desired_cols]\n",
        "mech_dummies = pd.get_dummies(total_frame['mechanics'], prefix='mech', drop_first=True)\n",
        "total_frame = pd.concat([total_frame, mech_dummies], axis=1)\n",
        "type_dummies = pd.get_dummies(total_frame['type'], prefix='type', drop_first=True)\n",
        "total_frame = pd.concat([total_frame, type_dummies], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# far more accurate with just recent years...\n",
        "tree_frame = total_frame[total_frame['year'] >= break_year]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62521\n62521\n"
          ]
        }
      ],
      "source": [
        "print(len(total_frame))\n",
        "print(len(tree_frame))"
      ]
    },
    {
      "source": [
        "#### filter out categorical columns for tree fitting"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 401,
      "metadata": {},
      "outputs": [],
      "source": [
        "# list of just desired features, now including one-hot cols and remove categorical cols\n",
        "features = list(tree_frame.columns)\n",
        "\n",
        "# remove either categorical cols or all cols\n",
        "features.remove('mechanics')\n",
        "# features.remove('categories')\n",
        "features.remove('type')\n",
        "\n",
        "# for col in desired_cols:\n",
        "#     features.remove(col)\n",
        "# print(features)"
      ]
    },
    {
      "source": [
        "### Divide the data set\n",
        "#### split data into training portions"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 402,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filtered features with one-hot fixes for categorical columns\n",
        "# keep categories for now for splitting into rows\n",
        "X = tree_frame[features]\n",
        "\n",
        "# target variable\n",
        "y = tree_frame[['categories']]\n",
        "\n",
        "# Split method, 0.3 == 30% of data saved for testing, choosen randomly from set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)"
      ]
    },
    {
      "source": [
        "### split X_train, X_test, and y_train so model can \"learn\" different categories separately\n",
        "### keep y_test.categories intact for y_prediction comparisons"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 403,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split training and x_test by category\n",
        "X_train = split_data_frame_list(X_train, 'categories')\n",
        "# X_test = split_data_frame_list(X_test, 'categories')\n",
        "y_train = split_data_frame_list(y_train, 'categories')\n",
        "\n",
        "# then remove categorical column\n",
        "X_train.drop('categories', inplace=True, axis=1)\n",
        "X_test.drop('categories', inplace=True, axis=1)\n",
        "\n",
        "# dupe instead of split for accuracy tests\n",
        "# y_test = dupe_data_frame_list(y_test, 'categories')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 404,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done!\n"
          ]
        }
      ],
      "source": [
        "# exploration\n",
        "# print(len(X.columns))\n",
        "# # features = list(X_train.columns)\n",
        "# # features.remove('categories')\n",
        "# print(len(X_train.columns))\n",
        "# X_train.drop('categories', inplace=True, axis=1)\n",
        "# X_test.drop('categories', inplace=True, axis=1)\n",
        "print(\"done!\")\n"
      ]
    },
    {
      "source": [
        "### Train the model "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q42-XPJjIyXv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "94c92518-3ea7-48e3-999c-762159548e53"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "best_acc = 0\n",
        "for j in range(1, 500):\n",
        "    # Decision Tree classifer object\n",
        "    dtc = DecisionTreeClassifier(criterion=\"entropy\", splitter='best', max_depth=20)\n",
        "\n",
        "    # Train Decision Tree Classifer\n",
        "    dtc = dtc.fit(X_train,y_train)\n",
        "\n",
        "    # predictions by model for y\n",
        "    y_pred = dtc.predict(X_test)\n",
        "\n",
        "    # custom accuracy check - NON-SPLIT DATA\n",
        "    correct = 0\n",
        "    y_targets = y_test[\"categories\"].tolist() \n",
        "    for i in range(len(y_pred)):\n",
        "        if y_pred[i] in y_targets[i]:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / len(y_pred)\n",
        "    if accuracy > best_acc:\n",
        "        best_dtc = deepcopy(dtc)\n",
        "        best_acc = accuracy\n",
        "        # print(\"depth: \", 20+j)\n",
        "        print(\"best acc: \", accuracy)\n",
        "\n",
        "print('done!')"
      ],
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best acc:  0.8771396576547752\n",
            "best acc:  0.8780461792779822\n",
            "best acc:  0.8787927264970938\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MemoryError",
          "evalue": "could not allocate 3670016 bytes",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-411-db771f8ad3af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Train Decision Tree Classifer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdtc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# predictions by model for y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \"\"\"\n\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree._add_node\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree._resize_c\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32msklearn\\tree\\_utils.pyx\u001b[0m in \u001b[0;36msklearn.tree._utils.safe_realloc\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mMemoryError\u001b[0m: could not allocate 3670016 bytes"
          ]
        }
      ]
    },
    {
      "source": [
        "### SAVE MODEL!! (and test accuracy of accuracy rating)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 370,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dtc_true_8766.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 370
        }
      ],
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "# swtich to model directory\n",
        "os.chdir(r\"C:\\Users\\Zack\\Desktop\\work\\OSU\\406 - p2 - learning\\jupyter practice\\final models\\models\")\n",
        "\n",
        "# create and save file\n",
        "joblib_file = \"dtc_true_8766.joblib\"  \n",
        "dump(best_dtc, joblib_file)"
      ]
    },
    {
      "source": [
        "#### load and test model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 371,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.876553084839759\n"
          ]
        }
      ],
      "source": [
        "# swtich to model directory\n",
        "os.chdir(r\"C:\\Users\\Zack\\Desktop\\work\\OSU\\406 - p2 - learning\\jupyter practice\\final models\\models\")\n",
        "joblib_model = load(joblib_file)\n",
        "\n",
        "y_pred = joblib_model.predict(X_test)\n",
        "\n",
        "# custom accuracy check\n",
        "correct = 0\n",
        "y_targets = y_test[\"categories\"].tolist() \n",
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] in y_targets[i]:\n",
        "        correct += 1\n",
        "\n",
        "print(\"Accuracy:\", correct / len(y_pred))"
      ]
    },
    {
      "source": [
        "#### test with different data"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {},
      "outputs": [],
      "source": [
        "# before year trimmed\n",
        "X = total_frame[features]\n",
        "y = total_frame[['categories']]\n",
        "\n",
        "# Split to new sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 380,
      "metadata": {},
      "outputs": [],
      "source": [
        "# new split/dupes\n",
        "# X_train = split_data_frame_list(X_train, 'categories')\n",
        "# X_test = split_data_frame_list(X_test, 'categories')\n",
        "# y_train = split_data_frame_list(y_train, 'categories')\n",
        "\n",
        "# then remove categorical column\n",
        "X_train.drop('categories', inplace=True, axis=1)\n",
        "X_test.drop('categories', inplace=True, axis=1)\n",
        "\n",
        "# dupe instead of split for accuracy tests\n",
        "# y_test = dupe_data_frame_list(y_test, 'categories')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9592152263155089\n"
          ]
        }
      ],
      "source": [
        "# new predictions\n",
        "y_pred = joblib_model.predict(X_test)\n",
        "\n",
        "# custom accuracy check\n",
        "correct = 0\n",
        "y_targets = y_test[\"categories\"].tolist() \n",
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] in y_targets[i]:\n",
        "        correct += 1\n",
        "\n",
        "print(\"Accuracy:\", correct / len(y_pred))"
      ]
    },
    {
      "source": [
        "### visualize training depths"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "max_depth = []\n",
        "acc_gini = []\n",
        "acc_entropy = []\n",
        "\n",
        "best_acc = correct / len(y_pred)\n",
        "best_dtc = dtc\n",
        "\n",
        "y_targets = y_test[\"categories\"].tolist() \n",
        "for i in range(1,36):\n",
        "    # testing entropy\n",
        "    dtree = DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=i)\n",
        "    dtree.fit(X_train, y_train)\n",
        "    y_pred = dtree.predict(X_test)\n",
        "    correct = 0\n",
        "    for j in range(len(y_pred)):\n",
        "        if y_pred[j] in y_targets[j]:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / len(y_pred)\n",
        "    acc_entropy.append(accuracy)\n",
        "    if accuracy > best_acc:\n",
        "        best_dtc = deepcopy(dtree)\n",
        "        best_acc = accuracy\n",
        "        print(\"best acc: \", accuracy)\n",
        "\n",
        "    # testing gini\n",
        "    dtree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=i)\n",
        "    dtree.fit(X_train, y_train)\n",
        "    y_pred = dtree.predict(X_test)\n",
        "    correct = 0\n",
        "    for j in range(len(y_pred)):\n",
        "        if y_pred[j] in y_targets[j]:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / len(y_pred)\n",
        "    acc_gini.append(accuracy)\n",
        "\n",
        "    if accuracy > best_acc:\n",
        "        best_dtc = deepcopy(dtree)\n",
        "        best_acc = accuracy\n",
        "        print(\"best acc: \", accuracy)\n",
        "\n",
        "    # track depth for values\n",
        "    max_depth.append(i)\n",
        "\n",
        "\n",
        "# data frame with tracked values to graph\n",
        "df = pd.DataFrame({'acc_gini':pd.Series(acc_gini), \n",
        "'acc_entropy':pd.Series(acc_entropy),\n",
        "'max_depth':pd.Series(max_depth)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib_file = \"dtc_8936.joblib\"  \n",
        "dump(best_dtc, joblib_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# graph folder\n",
        "os.chdir(r\"C:\\Users\\Zack\\Desktop\\work\\OSU\\406 - p2 - learning\\jupyter practice\\final models\\graphs\")\n",
        "\n",
        "#size \n",
        "sns.set(rc={'figure.figsize': (6, 6)})\n",
        "\n",
        "print(max_depth)\n",
        "# visualizing changes in parameters\n",
        "sns.lineplot(x='max_depth', y='acc_gini', data=df)\n",
        "sns.lineplot(x='max_depth', y='acc_entropy', data=df)\n",
        "plt.xlabel('max depth')\n",
        "plt.ylabel('accuracy')\n",
        "# plt.xlim(1,30)\n",
        "plt.savefig('gini vs entropy', bbox_inches = 'tight')\n",
        "plt.show()"
      ]
    },
    {
      "source": [
        "### Visualize training tree model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "from six import StringIO  \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "\n",
        "# dot_data = StringIO()\n",
        "# # number of unique values in target col\n",
        "# class_names = list(tree_frame.categories.unique())\n",
        "\n",
        "# # use trained decision tree model, feature columns, and clases in target col\n",
        "# export_graphviz(dtc, out_file = dot_data, filled=True, rounded=True, special_characters=True,\n",
        "#                 feature_names = features,\n",
        "#                 class_names = class_names)\n",
        "\n",
        "# # creates image and then displays in Jupyter\n",
        "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "# graph.write_png('game_classes.png')\n",
        "# Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}