{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KMeans_Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "source": [
        "# Score Prediction Regression Model"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "UID9RK1qDlVB",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO_1kOEGDTws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "eccc66bd-8b04-4d4f-faa1-b4b0d22df5c8"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "working_dir = os.getcwd()\n",
        "game_data = pd.read_csv('game_data.csv')\n",
        "game_data.head() # See the first 5 rows to check data import"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id       type         name  year  minplayers  maxplayers  playingtime  \\\n",
              "0     13  boardgame        Catan  1995           3           4          120   \n",
              "1    822  boardgame  Carcassonne  2000           2           5           45   \n",
              "2  30549  boardgame     Pandemic  2008           2           4           45   \n",
              "3  68448  boardgame    7 Wonders  2010           2           7           30   \n",
              "4  36218  boardgame     Dominion  2008           2           4           30   \n",
              "\n",
              "   minplaytime  maxplaytime  minage  ...  bay_rating  owners  traders  \\\n",
              "0           60          120      10  ...     7.00456  141505     1792   \n",
              "1           30           45       7  ...     7.31303  137009     1577   \n",
              "2           45           45       8  ...     7.52214  141355     2157   \n",
              "3           30           30      10  ...     7.66507  103879     1342   \n",
              "4           30           30      13  ...     7.52473   96360     1887   \n",
              "\n",
              "   wanters  wishers  total_comments  total_weights  complexity  \\\n",
              "0      463     5218           17610           7137      2.3277   \n",
              "1      539     6164           17506           7239      1.9171   \n",
              "2      650     8444           15545           5180      2.4154   \n",
              "3     1042    10713           13112           4360      2.3323   \n",
              "4      629     7478           12876           4820      2.3591   \n",
              "\n",
              "                                          categories  \\\n",
              "0                        ['Economic', 'Negotiation']   \n",
              "1  ['City Building', 'Medieval', 'Territory Build...   \n",
              "2                                        ['Medical']   \n",
              "3  ['Ancient', 'Card Game', 'City Building', 'Civ...   \n",
              "4                          ['Card Game', 'Medieval']   \n",
              "\n",
              "                                           mechanics  \n",
              "0  ['Dice Rolling', 'Hexagon Grid', 'Income', 'Mo...  \n",
              "1  ['Area Majority / Influence', 'Map Addition', ...  \n",
              "2  ['Action Points', 'Cooperative Game', 'Hand Ma...  \n",
              "3  ['Card Drafting', 'Drafting', 'Hand Management...  \n",
              "4  ['Deck / Bag / Pool Building', 'Delayed Purcha...  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>type</th>\n      <th>name</th>\n      <th>year</th>\n      <th>minplayers</th>\n      <th>maxplayers</th>\n      <th>playingtime</th>\n      <th>minplaytime</th>\n      <th>maxplaytime</th>\n      <th>minage</th>\n      <th>...</th>\n      <th>bay_rating</th>\n      <th>owners</th>\n      <th>traders</th>\n      <th>wanters</th>\n      <th>wishers</th>\n      <th>total_comments</th>\n      <th>total_weights</th>\n      <th>complexity</th>\n      <th>categories</th>\n      <th>mechanics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13</td>\n      <td>boardgame</td>\n      <td>Catan</td>\n      <td>1995</td>\n      <td>3</td>\n      <td>4</td>\n      <td>120</td>\n      <td>60</td>\n      <td>120</td>\n      <td>10</td>\n      <td>...</td>\n      <td>7.00456</td>\n      <td>141505</td>\n      <td>1792</td>\n      <td>463</td>\n      <td>5218</td>\n      <td>17610</td>\n      <td>7137</td>\n      <td>2.3277</td>\n      <td>['Economic', 'Negotiation']</td>\n      <td>['Dice Rolling', 'Hexagon Grid', 'Income', 'Mo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>822</td>\n      <td>boardgame</td>\n      <td>Carcassonne</td>\n      <td>2000</td>\n      <td>2</td>\n      <td>5</td>\n      <td>45</td>\n      <td>30</td>\n      <td>45</td>\n      <td>7</td>\n      <td>...</td>\n      <td>7.31303</td>\n      <td>137009</td>\n      <td>1577</td>\n      <td>539</td>\n      <td>6164</td>\n      <td>17506</td>\n      <td>7239</td>\n      <td>1.9171</td>\n      <td>['City Building', 'Medieval', 'Territory Build...</td>\n      <td>['Area Majority / Influence', 'Map Addition', ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30549</td>\n      <td>boardgame</td>\n      <td>Pandemic</td>\n      <td>2008</td>\n      <td>2</td>\n      <td>4</td>\n      <td>45</td>\n      <td>45</td>\n      <td>45</td>\n      <td>8</td>\n      <td>...</td>\n      <td>7.52214</td>\n      <td>141355</td>\n      <td>2157</td>\n      <td>650</td>\n      <td>8444</td>\n      <td>15545</td>\n      <td>5180</td>\n      <td>2.4154</td>\n      <td>['Medical']</td>\n      <td>['Action Points', 'Cooperative Game', 'Hand Ma...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>68448</td>\n      <td>boardgame</td>\n      <td>7 Wonders</td>\n      <td>2010</td>\n      <td>2</td>\n      <td>7</td>\n      <td>30</td>\n      <td>30</td>\n      <td>30</td>\n      <td>10</td>\n      <td>...</td>\n      <td>7.66507</td>\n      <td>103879</td>\n      <td>1342</td>\n      <td>1042</td>\n      <td>10713</td>\n      <td>13112</td>\n      <td>4360</td>\n      <td>2.3323</td>\n      <td>['Ancient', 'Card Game', 'City Building', 'Civ...</td>\n      <td>['Card Drafting', 'Drafting', 'Hand Management...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>36218</td>\n      <td>boardgame</td>\n      <td>Dominion</td>\n      <td>2008</td>\n      <td>2</td>\n      <td>4</td>\n      <td>30</td>\n      <td>30</td>\n      <td>30</td>\n      <td>13</td>\n      <td>...</td>\n      <td>7.52473</td>\n      <td>96360</td>\n      <td>1887</td>\n      <td>629</td>\n      <td>7478</td>\n      <td>12876</td>\n      <td>4820</td>\n      <td>2.3591</td>\n      <td>['Card Game', 'Medieval']</td>\n      <td>['Deck / Bag / Pool Building', 'Delayed Purcha...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 22 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_pPmK9GIKMz",
        "colab_type": "text"
      },
      "source": [
        "## clean and filter data\n",
        "\n",
        "#### selective filtering for removing extremes, retain 'game_data' in case any reference to complete set is needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WevSKogFEalU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "dc31b65e-b7f5-4116-ec89-5790fdb604bc"
      },
      "source": [
        "bgg_games = game_data[game_data['year'] > 1980]\n",
        "bgg_games = bgg_games[bgg_games['maxplayers'] <= 30]\n",
        "bgg_games = bgg_games[bgg_games['minplaytime'] <= 180] # 120 - 90th percentile\n",
        "bgg_games = bgg_games[bgg_games['maxplaytime'] <= 720]\n",
        "bgg_games = bgg_games[bgg_games['minage'] <= 21]\n",
        "bgg_games = bgg_games[bgg_games['playingtime'] >= 10]\n",
        "bgg_games = bgg_games[bgg_games['maxplayers'] >= bgg_games['minplayers']]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [
        "#### select cells potentially relevant to rating (before community interaction)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtc_test = bgg_games[['type', 'minplayers', 'maxplayers', 'playingtime',\n",
        "       'minplaytime', 'maxplaytime', 'minage', 'avg_rating', 'mechanics',\n",
        "       'bay_rating', 'total_comments', 'total_weights', 'complexity', 'categories']]"
      ]
    },
    {
      "source": [
        "#### convert mechanics and categories into lists with values"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtc_test['categories'] = dtc_test['categories'].apply(lambda x: x.strip('][').split(', ') )\n",
        "dtc_test['mechanics'] = dtc_test['mechanics'].apply(lambda x: x.strip('][').split(', ') )"
      ]
    },
    {
      "source": [
        "#### count number of mechanics and categories for each game, make new columns"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtc_test['num_mechs'] = dtc_test.apply(lambda row: len(row['mechanics']), axis=1)\n",
        "dtc_test['num_cats'] = dtc_test.apply(lambda row: len(row['categories']), axis=1)\n",
        "dtc_test['player_diff'] = dtc_test.maxplayers - dtc_test.minplayers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_data_frame_list(df, target_column, output_type=str):\n",
        "    ''' \n",
        "    Accepts a column with list values and splits into several rows.\n",
        "\n",
        "    df: dataframe to split\n",
        "    target_column: the column containing the values to split\n",
        "    output_type: type of all outputs\n",
        "    returns: a dataframe with each entry for the target column separated, with each element moved into a new row. \n",
        "    The values in the other columns are duplicated across the newly divided rows.\n",
        "    '''\n",
        "    row_accumulator = []\n",
        "\n",
        "    def split_list_to_rows(row):\n",
        "        split_row = row[target_column]\n",
        "        if isinstance(split_row, list):\n",
        "          for s in split_row:\n",
        "              new_row = row.to_dict()\n",
        "              new_row[target_column] = output_type(s)\n",
        "              row_accumulator.append(new_row)\n",
        "        else:\n",
        "          new_row = row.to_dict()\n",
        "          new_row[target_column] = output_type(split_row)\n",
        "          row_accumulator.append(new_row)\n",
        "  \n",
        "    df.apply(split_list_to_rows, axis=1)\n",
        "    new_df = pd.DataFrame(row_accumulator)\n",
        "  \n",
        "    return new_df"
      ]
    },
    {
      "source": [
        "#### split lists into multiple rows for regression model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtc_test = split_data_frame_list(dtc_test, 'categories')\n",
        "dtc_test = split_data_frame_list(dtc_test, 'mechanics')"
      ]
    },
    {
      "source": [
        "#### get all desired cols and apply one-hot fix to categorical features"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# for filtering cols\n",
        "desired_cols = ['type', 'minplayers', 'maxplayers', 'playingtime', 'minplaytime', 'maxplaytime', 'minage', 'avg_rating', 'bay_rating', 'complexity', 'categories', 'mechanics', 'num_mechs', 'num_cats', 'player_diff']\n",
        "\n",
        "# make dummies (one-hot fix) for categorical values\n",
        "# will remove categorical columns as well\n",
        "model_frame = dtc_test[desired_cols]\n",
        "model_frame = pd.get_dummies(model_frame, drop_first=True)"
      ]
    },
    {
      "source": [
        "#### filter out columns for model fitting"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# list of just desired features, now including one-hot cols\n",
        "features = list(model_frame.columns)\n",
        "\n",
        "# remove target cols\n",
        "features.remove('avg_rating')\n",
        "features.remove('bay_rating')"
      ]
    },
    {
      "source": [
        "## Divide the data set\n",
        "#### split data into training and testing portions"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# filtered features with one-hot fixes for categorical columns\n",
        "X = model_frame[features]\n",
        "\n",
        "# remove undesired columns\n",
        "X.drop(\"categories_'Expansion for Base-game'\", inplace=True, axis=1) # duplicate of \"is expansion\"\n",
        "\n",
        "# target variable - average because bays is weighted so heavily\n",
        "y = model_frame[['avg_rating']]\n",
        "\n",
        "# Split data - limit training because it will be filtered and re-allocated later\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.0001, random_state=1)"
      ]
    },
    {
      "source": [
        "### feature selection"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
        "from functools import partial\n",
        "\n",
        "# f_regression is univarite - direct correlations\n",
        "# mutual_info compares multiple feature pairs\n",
        "\n",
        "def feature_selection(X_train, y_train, m=0, n='all'):\n",
        "\t'''produces feature values to help with selection\n",
        "\tIN: 3 frames split from data\n",
        "\t\tm = type of method desired (int)\n",
        "\t\tn = number of top features to select\n",
        "\tOUT: transformed X-data and feature selection model'''\n",
        "\n",
        "\t# partial to establish params for mutual info\n",
        "\t# CAN'T HANDLE\n",
        "\tmutual_info = partial(mutual_info_regression, random_state=0)\n",
        "\n",
        "\t# scoring functions to use\n",
        "\tmethods = [f_regression, mutual_info]\n",
        "\n",
        "\t# configure to select type of feature value grader and number of top features to track\n",
        "\tfs = SelectKBest(score_func=methods[m], k=n)\n",
        "\n",
        "\t# correlate relationships from training data\n",
        "\tfs.fit(X_train, y_train)\n",
        "\n",
        "\treturn fs"
      ]
    },
    {
      "source": [
        "#### feature selection parameters for filtering columns into regression model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# feature selection scores (currently set to check all features)\n",
        "fs = feature_selection(X_train, y_train, 0, 15)\n",
        "feature_mask = fs.get_support()\n",
        "top_features = X.columns[feature_mask]"
      ]
    },
    {
      "source": [
        "### reset test data for mutual information filtering"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = model_frame[top_features]\n",
        "\n",
        "# still the same\n",
        "y = model_frame[['avg_rating']]\n",
        "\n",
        "# new data split for training with limited set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # DANGER DANGER\n",
        "# # new feature selection model\n",
        "# fs_mut = feature_selection(X_train, y_train, 1, 15)\n",
        "# feature_mask = fs.get_support()\n",
        "# top_features = X.columns[feature_mask]\n",
        "# print(top_features)"
      ]
    },
    {
      "source": [
        "## Train the model "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q42-XPJjIyXv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "94c92518-3ea7-48e3-999c-762159548e53"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from copy import deepcopy\n",
        "import math\n",
        "\n",
        "# for checking accuracy\n",
        "best_r2 = 0\n",
        "best_mse = math.inf\n",
        "\n",
        "# random forest regressor creates many regression trees for evaluation\n",
        "rfr = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42)\n",
        "\n",
        "# fit model to training data\n",
        "rfr.fit(X_train,y_train)\n",
        "\n",
        "# predictions by model for y\n",
        "y_pred = rfr.predict(X_test)\n",
        "\n",
        "# accuracy check, lower is better\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('MSE Forest: ', mse)\n",
        "\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('r2 Forest: ', r2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Forest:  0.050877176437359596\nr2 Forest:  0.9411821686719545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target score:  avg_rating    8.22286\nName: 42866, dtype: float64\npredicted score:  8.218860365220493\n"
          ]
        }
      ],
      "source": [
        "# check specific instances for accuracy\n",
        "target = 170 # must be smaller than dataframe length and >=0\n",
        "print(\"target score: \", y_test.iloc[target])\n",
        "print(\"predicted score: \", y_pred[target])"
      ]
    },
    {
      "source": [
        "### save model and test accuracy of accuracy rating"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE:  0.050877176437359596\nr2:  0.9411821686719545\n"
          ]
        }
      ],
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "# swtich to model directory\n",
        "model_dir = working_dir + \"\\models\"\n",
        "os.chdir(model_dir)\n",
        "\n",
        "# create and save file\n",
        "# [model type]_[details]_[accuracy]\n",
        "joblib_file = \"rfr_test_9412.joblib\"  \n",
        "dump(rfr, joblib_file)\n",
        "\n",
        "# test load\n",
        "joblib_model = load(joblib_file)\n",
        "\n",
        "y_pred = joblib_model.predict(X_test)\n",
        "\n",
        "# accuracy check\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('MSE: ', mse)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('r2: ', r2)"
      ]
    },
    {
      "source": [
        "### load and test model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# swtich to model directory\n",
        "model_dir = working_dir + \"\\models\"\n",
        "os.chdir(model_dir)\n",
        "\n",
        "# file name with model to load\n",
        "joblib_file = \"rfr_test_9412.joblib\"  \n",
        "joblib_model = load(joblib_file)"
      ]
    },
    {
      "source": [
        "#### re-load data to check against different set, after initial test\n",
        "##### (needs to be run twice for some reason...)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = model_frame[top_features]\n",
        "\n",
        "# still the same\n",
        "y = model_frame[['avg_rating']]\n",
        "\n",
        "# new data split for training with limited set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=24)"
      ]
    },
    {
      "source": [
        "#### re-test model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE:  0.039372519846675114\nr2:  0.9547505971722409\n"
          ]
        }
      ],
      "source": [
        "# model prediction scores\n",
        "y_pred = joblib_model.predict(X_test)\n",
        "\n",
        "# accuracy check\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('MSE: ', mse)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('r2: ', r2)"
      ]
    }
  ]
}